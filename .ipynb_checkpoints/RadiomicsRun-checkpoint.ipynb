{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time, sys, pickle, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler, Robustscaler\n",
    "from datetime import datetime\n",
    "from Modelling.VariableSelect import  ModelVarSelect,CorrVarSelect\n",
    "from options.options import get_options\n",
    "from Modelling.MachineLearning import MachineLearning\n",
    "from Utils.ExtractRadiomics import *\n",
    "from scripts.Experiments import *\n",
    "from Utils.Performance import *\n",
    "from Utils.Utils import *\n",
    "opt = get_options()\n",
    "random.seed(opt.random_seed)\n",
    "np.random.seed(opt.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of radiomics based on paths in a dictionary with structure\n",
    "# key=ID : value=dict --> key='segmentations','NCCT' : value=\n",
    "# segmentations and NCCT refer to a path to a segmenataion and corresponding NCCT scan to obtain \n",
    "\n",
    "#### Radiomics extraction and storage in df ####\n",
    "extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "\n",
    "done_IDs = []\n",
    "out, c = [], 0\n",
    "for ID,v in tqdm(dct.items()):\n",
    "    if len(v['segmentations'])>1:\n",
    "        c+=1\n",
    "        p_ncct = v['NCCT']\n",
    "        for count,(name,p_seg) in enumerate(v['segmentations'].items()):\n",
    "            #iterate over segmentations and compute radiomic values --> store the values in the dict\n",
    "            name = p_seg.split('\\\\')[-1].split('.')[0].split('_')[-1]\n",
    "            print(name)\n",
    "            s = sitk.GetArrayFromImage(sitk.ReadImage(p_seg))\n",
    "            if s.sum()<10:\n",
    "                print(ID,'no segmentation available', p_seg)\n",
    "                continue\n",
    "            try:\n",
    "                result = extractor.execute(p_ncct, p_seg)\n",
    "                sers = Radiomics2pandas(result)\n",
    "                sers['ID'] = ID\n",
    "                sers['observer'] = name\n",
    "                sers['path_seg'] = p_seg\n",
    "                sers['path_ncct'] = p_ncct\n",
    "                out.append(sers)\n",
    "                print(ID,p_seg)\n",
    "            except:\n",
    "                print(ID,'error')\n",
    "\n",
    "df = pd.concat(out, axis=1).T\n",
    "df.to_excel(os.path.join(root_output,'data_radiomics.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(output_folder='C:\\\\Users\\\\henkvanvoorst\\\\Documents\\\\phd\\\\trombus radiomix\\\\results_wine', output_type='binary', xvars=None, yvar=None, random_seed=11, ordinal_thresh=3, n_trees=100, n_splits=5, simple_best=True, scoring=None, best_score='highest', min_icc=0.75, min_importance=0.001, importance_pct=False, filter_top_n=100, filter_top_n_radiomics=3, split_shape_intensity_radiomics=True, optimize_prob_thresh=True, max_corr=0.6, corr_type='spearman', custom_loss='binary:logistic', cache_size=1000, bootstrap=100, n_jobs=4)\n",
      "Total available radiomic variables: 107\n",
      "Radiomic variables with ICC2k>0.75: 51\n",
      "Total x variables available: 73\n",
      "Number of binary, ordinal, continuous, and manual thrombus measurement variables 11 3 5 3\n",
      "(699, 73) (499, 73) (200, 73) (499, 9) (200, 9)\n",
      "(699, 73) (499, 73) (200, 73) (499, 9) (200, 9)\n",
      "73 19 3 51 ['total_attempts', 'FPR', 'ThreePR', 'GoodmRS', 'mrs_rev', 'attempts_to_succes', 'posttici_c', 'TICI_2B-3', 'n_attempt_0-3']\n"
     ]
    }
   ],
   "source": [
    "# this step requires a merged data file (file)\n",
    "\n",
    "opt = get_options()\n",
    "seed = 11\n",
    "#fix random seed\n",
    "opt.random_seed = seed\n",
    "print(opt)\n",
    "random.seed(opt.random_seed)\n",
    "np.random.seed(opt.random_seed)\n",
    "\n",
    "## datafile with all the x and y variables (CV,MTM,RV)\n",
    "file = r'data_to_use.xlsx'\n",
    "#path to ICC file with each variable and their ICC-value (used for feature selection)\n",
    "p_icc= r'icc3k.xlsx'\n",
    "#define a folder for your output\n",
    "root_output = r'results_robscale_'+str(seed)\n",
    "\n",
    "# all variables are in the import_data function defined and pre-selected based on ICC\n",
    "xvars, [cv_bin, cv_ord, cv_cont,mtm, radiomic_vars, vars_to_norm], outcomes, df = import_data(file, p_icc,opt.min_icc)\n",
    "cv = [*cv_bin, *cv_ord, *cv_cont] #clinical vars\n",
    "df = pd.read_excel(file) #input data should have no missing data points (for some algorithms, not RF)\n",
    "\n",
    "#split train and test sets\n",
    "path_ID = os.path.join(root_output,'train_test')\n",
    "testID, trainID = train_test_ID(df.ID, test_size=200,seed=opt.random_seed,root_store=path_ID)\n",
    "train_pid = os.path.join(path_ID,'train_ID.xlsx')\n",
    "test_pid = os.path.join(path_ID,'test_ID.xlsx')\n",
    "#load train and test data, apply scaling if required\n",
    "df_train, df_test = load_train_test_norm(train_pid, test_pid, df, xvars, outcomes, vars_to_norm, scaler=RobustScaler())\n",
    "df_train_noscale, df_test_noscale = split_train_test_norm(df,xvars,outcomes, vars_to_norm, test_size=200, scaler=None, seed=opt.random_seed)\n",
    "print(len(xvars), len(cv),len(mtm),len(radiomic_vars), outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define grid for analyses\n",
    "\n",
    "#Outcomes to analyse\n",
    "YVAR = ['GoodmRS', 'FPR', 'ThreePR', 'TICI_2B-3']\n",
    "#xvars select for each experiment (key is the output folder)\n",
    "XVARS = {'cv_mtm_rv':[*cv,*mtm,*radiomic_vars], \n",
    "         'cv_mtm':[*cv,*mtm], \n",
    "         'cv_rv':[*cv,*radiomic_vars], \n",
    "         'rv':[*radiomic_vars],\n",
    "         'mtm':[*mtm],\n",
    "         'cv':[*cv]\n",
    "        } #set of variables for experiments\n",
    "\n",
    "#use feature selection\n",
    "SKIPFILTER = [False]#[True,False] # skip all the filtering steps --> directly fit top model\n",
    "# feature selection algo = final algo : XGB, RF, LR\n",
    "ALGOS = ['RF'] # algoritms considered, alternative options: ['RF', 'LR', 'XGB', 'SVM'] \n",
    "#n_top radiomics features selected for final model based on importance metric, (100 is all)\n",
    "TOPN = [100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run all the experiments (might take some time)\n",
    "for yvar in tqdm(YVAR):\n",
    "    for xk, xvars in XVARS.items():\n",
    "        for skipfilter in SKIPFILTER:\n",
    "            for algo in ALGOS:\n",
    "                for topn in TOPN:\n",
    "                    print('Running:',yvar,xk,topn,skipfilter)\n",
    "                    opt = get_options()\n",
    "                    opt.random_seed = seed\n",
    "                    opt.output_folder = os.path.join(root_output,yvar,xk, 'topn_'+str(topn)+'_'+str(skipfilter))\n",
    "                    opt.filter_top_n_radiomics = topn\n",
    "                    opt.n_jobs = 8\n",
    "                    opt.output_type = 'binary'\n",
    "                    \n",
    "                    if algo=='SVM':\n",
    "                        algo1,algo2 = 'RF','SVM'\n",
    "                    else:\n",
    "                        algo1, algo2 = algo,algo\n",
    "                     # first algorithm is used for feature selection second for prediction modelling\n",
    "                    \n",
    "                    file_add = ''# name to add to output file'_'+algo+'_topn_'+str(topn)+'_'+str(skipfilter)\n",
    "                    #initializes variable selection and prediction moddeling\n",
    "                    MVS = ModelVarSelect(opt,verbal=True)\n",
    "                    CVS = CorrVarSelect(opt,verbal=True)\n",
    "                    ML = MachineLearning(opt,verbal=True)\n",
    "                    try:\n",
    "                        MVS,CVS,ML = run_experiment(MVS,CVS,ML,opt,\n",
    "                                                    df_train,df_test, \n",
    "                                                    xvars, yvar, None,\n",
    "                                                    mdlname=algo1,addname=file_add, \n",
    "                                                    finmdlname=algo2, skip_filter=skipfilter)\n",
    "                        print(ML.res_test)\n",
    "                    except:\n",
    "                        print('Error working experiment:', file_add)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### aggregate all results to final tables\n",
    "\n",
    "valout = []\n",
    "out = []\n",
    "bootstrap_res = []\n",
    "for yvar in tqdm(YVAR):\n",
    "    for xk, xvars in XVARS.items():\n",
    "        for skipfilter in SKIPFILTER:\n",
    "            for topn in TOPN:\n",
    "                algo = 'RF'\n",
    "                opt = get_options()\n",
    "                opt.output_folder = os.path.join(root_output,yvar,xk, \n",
    "                            'topn_'+str(topn)+'_'+str(skipfilter))\n",
    "       \n",
    "                f = os.path.join(opt.output_folder,'RF','6.variable_importance_final.xlsx') #top 3 features\n",
    "                fval = os.path.join(opt.output_folder,algo,'1.gridsearch_results_final.xlsx') #validation AUC\n",
    "                f2 = os.path.join(opt.output_folder,algo,'3.test_results_final.xlsx') #test AUC and other results\n",
    "                \n",
    "                MVS = ModelVarSelect(opt,verbal=True)\n",
    "                CVS = CorrVarSelect(opt,verbal=True)\n",
    "                ML = MachineLearning(opt,verbal=True)\n",
    "                \n",
    "                #if yvar=='GoodmRS' and xk=='cv_mtm_rv':\n",
    "                    #load final rf model\n",
    "                    #get_feature_importance(self,model)\n",
    "                \n",
    "                #Compute all test set results per experiment\n",
    "                if not os.path.exists(f2):\n",
    "                    print('Error no test results', f2)\n",
    "                    continue\n",
    "                tmp2 = pd.read_excel(f2)\n",
    "                tmp2.columns=['measure', 'score']\n",
    "                tmp2.index = tmp2['measure']\n",
    "                tmp2 = tmp2.drop(columns=['measure']).T\n",
    "                tmp2['xvariables'] = xk\n",
    "                tmp2['topn'] = topn\n",
    "                tmp2['skipfilter'] = skipfilter\n",
    "                tmp2['yvar'] = yvar\n",
    "                out.append(tmp2)\n",
    "                \n",
    "                #Compute validation set results and test together, add fi of top models\n",
    "                if not os.path.exists(fval):\n",
    "                    print('Error', opt.output_folder)\n",
    "                    continue               \n",
    "                tmp = pd.read_excel(f)\n",
    "                tmp.columns =['variables', 'fi']\n",
    "                tmp.index = tmp['variables']\n",
    "                tmp = tmp.loc[[ix for ix in tmp.index if 'original' in ix]]\n",
    "                top_shape, top_intensity, top_firstorder = CVS.separate_radiomics_n_important_variables(pd.DataFrame(tmp['fi']), 3)               \n",
    "                \n",
    "                val = pd.read_excel(fval)\n",
    "                test_AUC = tmp2['AUC_prob'].values[0]\n",
    "                val_AUC = round(val.mean_test_AUC.iloc[0],4)*100\n",
    "                val_std_AUC = round(val.std_test_AUC.iloc[0],4)*100\n",
    "                \n",
    "                \n",
    "                top_shape, top_intensity, top_firstorder = list(top_shape), list(top_intensity), list(top_firstorder)\n",
    "                while len(top_shape)!=3:\n",
    "                    top_shape.append(np.NaN)\n",
    "                while len(top_intensity)!=3:\n",
    "                    top_intensity.append(np.NaN)\n",
    "                while len(top_firstorder)!=3:\n",
    "                    top_firstorder.append(np.NaN)\n",
    "                \n",
    "                row = [yvar, xk, topn,skipfilter,*top_shape,*top_intensity,*top_firstorder,test_AUC, val_AUC, val_std_AUC]\n",
    "                #print(row)\n",
    "                valout.append(row)\n",
    "                \n",
    "                f_train_boot = os.path.join(opt.output_folder,algo,'4.train_results_bootstrap_final.xlsx') #test AUC and other results\n",
    "                f_test_boot = os.path.join(opt.output_folder,algo,'5.test_results_bootstrap_final.xlsx') #test AUC and other results\n",
    "                btrain = pd.read_excel(f_train_boot).drop(columns='Unnamed: 0')\n",
    "                btest = pd.read_excel(f_test_boot).drop(columns='Unnamed: 0')\n",
    "                \n",
    "                tmp_train = btrain.describe().T\n",
    "                tmp_test = btest.describe().T\n",
    "                \n",
    "                boot = tmp_train.merge(tmp_test, left_index=True, right_index=True, suffixes=('_test', '_train')).reset_index()\n",
    "                boot['yvar'] = yvar\n",
    "                boot['xvars'] = xk\n",
    "                boot['topn'] = topn\n",
    "                boot['skipfilter'] = skipfilter\n",
    "                bootstrap_res.append(boot)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reports top importance radiomic features\n",
    "df_importance = pd.DataFrame(valout,columns=['yvar', 'xvars', \n",
    "                                            'skipfilter', 'topn',\n",
    "                                            'shape1', 'shape2', 'shape3', \n",
    "                                            'int1', 'int2', 'int3', 'fo1', 'fo2', 'fo3',\n",
    "                                            'AUC_test', 'AUC_val', 'AUC_std_val'])\n",
    "df_importance.to_excel(os.path.join(root_output,'test_results.xlsx'))\n",
    "\n",
    "#reports all metrics of a feature\n",
    "df_performance = pd.concat(out)\n",
    "df_performance.to_excel(os.path.join(root_output,'test_all_metrics.xlsx'))\n",
    "\n",
    "#bootstrap results (for std/confidence interval construction in test set)\n",
    "Bres = pd.concat(bootstrap_res)\n",
    "Bres.to_excel(os.path.join(root_output,'bootstrap_aggregated.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
